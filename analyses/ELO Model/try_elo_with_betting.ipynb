{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.logit.base import get_match_result_data\n",
    "\n",
    "df, player_mapping, inverse_player_mapping = get_match_result_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddhantjagadish/Documents/DataProjects/tennis_modeling/tennis_modeling/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.sort('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['date'] < '2016-01-01'].copy()\n",
    "val_df = df[\n",
    "    (df['date'] >= '2016-01-01') &\n",
    "    (df['date'] < '2017-01-01')\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.logit.base import get_X_y\n",
    "\n",
    "train_X, train_y = get_X_y(train_df, player_mapping)\n",
    "val_X, val_y = get_X_y(val_df, player_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from models.logit.base import sipko_weights\n",
    "\n",
    "weights = sipko_weights(train_df['date'].max(), train_df, 0.8)\n",
    "plt.plot(range(len(weights)), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune flat time, decay weights\n",
    "Let's tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ml.prior_logit import NonZeroLogit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "N_ATTEMPTS = 50\n",
    "LMBDA = 100.\n",
    "PRIOR = -2.\n",
    "\n",
    "flat_times = np.linspace(0., 2., 11)\n",
    "decay_weights = np.linspace(0., 2., 21)\n",
    "\n",
    "perfs = []\n",
    "for ft in flat_times:\n",
    "    for dw in decay_weights:\n",
    "        print (ft, dw)\n",
    "        weights = sipko_weights(train_df['date'].max(), train_df, dw, flat_time=ft)\n",
    "        nzl = NonZeroLogit(lmbda=LMBDA, prior=PRIOR, seed=10)\n",
    "        nzl.fit(train_X, train_y, sample_weight=weights)\n",
    "        val_preds = nzl.predict_proba(val_X)[:, 1]\n",
    "        auc = roc_auc_score(val_df['y'], val_preds)\n",
    "        accuracy = (val_df['y'] == (val_preds > 0.5).astype(int)).mean()\n",
    "        perfs.append((dw, ft, auc, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(\n",
    "    perfs,\n",
    "    columns=[\n",
    "        'disc',\n",
    "        'ft',\n",
    "        'auc',\n",
    "        'accuracy'\n",
    "    ]\n",
    ")\n",
    "perf_df.sort('auc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df[perf_df['ft'] == 1.].sort('auc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(perf_df['disc'], perf_df['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(perf_df['ft'], perf_df['auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a discount factor of 0.6  does the trick..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.prior_logit import NonZeroLogit\n",
    "from models.logit.base import _get_weights\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "nzl = NonZeroLogit(lmbda=2., prior=-2.)\n",
    "weights = _get_weights(train_df['date'].max(), train_df, halflife=365.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nzl.fit(train_X, train_y, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nzl.predict_proba(val_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "val_df['pred'] = preds\n",
    "train_df['pred'] = nzl.predict_proba(train_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsotonicRegression()\n",
    "iso.fit(train_df['pred'], train_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['cal_pred'] = iso.predict(val_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(val_df['y'], val_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (val_df['y'] == (val_df['cal_pred'] > 0.5)).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.calibration import calibration_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "_x, _y = calibration_curve(val_df['y'], val_df['cal_pred'])\n",
    "plt.plot(_x, _y)\n",
    "plt.plot(_x, _x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Betting Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_betting(val_df, buff=0):\n",
    "    val_df['bet1'] = (1. / val_df['p1_odds']) < (val_df['cal_pred'] - buff)\n",
    "    val_df['bet2'] = (1. / val_df['p2_odds']) < (1. - val_df['cal_pred'] - buff)\n",
    "    bet_revenues = (\n",
    "        val_df['p1_odds'] * val_df['bet1'] * val_df['y']  +\n",
    "        val_df['p2_odds'] * val_df['bet2'] * (1. - val_df['y'])\n",
    "    )\n",
    "    bet_spending = val_df['bet1'] + val_df['bet2']\n",
    "    profit_over_time = bet_revenues.cumsum() - bet_spending.cumsum()\n",
    "    \n",
    "    total_placed = bet_spending.sum()\n",
    "    total_won = (val_df['bet1'] * val_df['y']).sum() + (val_df['bet2'] * (1. - val_df['y'])).sum()\n",
    "    return bet_revenues.sum() - bet_spending.sum(), profit_over_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_won, over_time = evaluate_betting(val_df)\n",
    "plt.plot(over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_won"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to always betting on player 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we lose money if we just choose a random player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_df = val_df.copy()\n",
    "new_val_df['cal_pred'] = 0.\n",
    "\n",
    "units_won, over_time = evaluate_betting(new_val_df)\n",
    "plt.plot(over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we lose a ton of money by randomly choosing a player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "val_df['tot_probs'] = ((1 / val_df['p1_odds']) + (1. / val_df['p2_odds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[['p1_odds', 'p2_odds', 'winner', 'loser', 'maxw', 'maxl', 'tot_probs']][val_df['tot_probs'] < 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
